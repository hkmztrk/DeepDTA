{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PhazeRoOman/DeepDTA/blob/Anas's-branch/Implementing_DeepDTA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMWqMkwR46uf",
        "outputId": "77d47a24-b4fa-400b-d34b-a6bcf4449ddb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlkPV_qabCyU"
      },
      "source": [
        "/content/drive/MyDrive/DSP_Team/DeepDTA/source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CqZypFa6jBF",
        "outputId": "15b095f5-3206-4320-dd68-8eff5fee9e0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DSP_Team/DeepDTA/source\n",
            "arguments.py  datahelper.py  go.sh                       \u001b[0m\u001b[01;34m__pycache__\u001b[0m/\n",
            "auc.jar       emetrics.py    Implementing_DeepDTA.ipynb  run_experiments.py\n",
            "\u001b[01;34mdata\u001b[0m/         \u001b[01;34mfigures\u001b[0m/       \u001b[01;34mlogs\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/DSP_Team/DeepDTA/source\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piPyqJyk8UUD",
        "outputId": "56f33207-fc42-42e8-e2d2-544708a449b3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 220\n",
            "-rw-------  1 root root   2797 Aug  9 13:51 arguments.py\n",
            "-rw-------  1 root root  10869 Aug  9 13:51 auc.jar\n",
            "drwx------  4 root root   4096 Aug  9 13:51 \u001b[0m\u001b[01;34mdata\u001b[0m/\n",
            "-rw-------  1 root root   5356 Aug 12 19:07 datahelper.py\n",
            "-rw-------  1 root root   2099 Aug  9 13:51 emetrics.py\n",
            "drwx------  2 root root   4096 Aug 12 18:04 \u001b[01;34mfigures\u001b[0m/\n",
            "-rw-------  1 root root    518 Aug  9 13:51 go.sh\n",
            "-rw-------  1 root root 162984 Aug 13 16:05 Implementing_DeepDTA.ipynb\n",
            "drwx------ 28 root root   4096 Aug 12 18:04 \u001b[01;34mlogs\u001b[0m/\n",
            "drwx------  2 root root   4096 Aug 12 18:04 \u001b[01;34m__pycache__\u001b[0m/\n",
            "-rw-------  1 root root  21520 Aug  9 13:51 run_experiments.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install matplotlib==3.3"
      ],
      "metadata": {
        "id": "1V97YSqY6fzs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip show matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baba-saR6ev0",
        "outputId": "42cd52b0-0b78-48a7-d64d-a95ab2be7dbd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: matplotlib\n",
            "Version: 3.3.0\n",
            "Summary: Python plotting package\n",
            "Home-page: https://matplotlib.org\n",
            "Author: John D. Hunter, Michael Droettboom\n",
            "Author-email: matplotlib-users@python.org\n",
            "License: PSF\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: cycler, kiwisolver, numpy, pillow, pyparsing, python-dateutil\n",
            "Required-by: arviz, datascience, fastai, imgaug, matplotlib-venn, missingno, mizani, mlxtend, music21, plotnine, prophet, pycocotools, seaborn, wordcloud, yellowbrick\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install transformers"
      ],
      "metadata": {
        "id": "L1UmOgJqiAXo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip show transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dchUQITh7vo",
        "outputId": "28f87cc2-6e5f-488a-81db-b9b73d70ca0b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: transformers\n",
            "Version: 4.31.0\n",
            "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
            "Home-page: https://github.com/huggingface/transformers\n",
            "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
            "Author-email: transformers@huggingface.co\n",
            "License: Apache 2.0 License\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Mq3tY2jw6mJx"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "from collections import namedtuple\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random as rn\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "\n",
        "np.random.seed(1)\n",
        "rn.seed(1)\n",
        "\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "tf.compat.v1.keras.backend.set_session\n",
        "tf.random.set_seed(0)\n",
        "\n",
        "from itertools import product"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpOt6jl6EFzs",
        "outputId": "29a9204e-ee7b-4721-af93-9661e1e704f5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "arguments.py  datahelper.py  go.sh                       \u001b[0m\u001b[01;34m__pycache__\u001b[0m/\n",
            "auc.jar       emetrics.py    Implementing_DeepDTA.ipynb  run_experiments.py\n",
            "\u001b[01;34mdata\u001b[0m/         \u001b[01;34mfigures\u001b[0m/       \u001b[01;34mlogs\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "H-PLHlOUdcw_"
      },
      "outputs": [],
      "source": [
        "import datahelper\n",
        "import arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Ox6k2ADDXP5r"
      },
      "outputs": [],
      "source": [
        "from datahelper import *\n",
        "from arguments import argparser, logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "jV1WNLQm6mM2"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Conv2D, GRU\n",
        "from keras.layers import Input, Embedding, LSTM, Dense, TimeDistributed, Masking, RepeatVector, Flatten\n",
        "from keras.models import Model\n",
        "from keras.utils import plot_model\n",
        "from keras.layers import Bidirectional\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras import optimizers, layers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ZYd98VL1XoLz"
      },
      "outputs": [],
      "source": [
        "import sys, pickle, os\n",
        "import math, json, time\n",
        "import decimal\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.mlab as mlab\n",
        "from random import shuffle\n",
        "from copy import deepcopy\n",
        "from sklearn import preprocessing\n",
        "from emetrics import get_aupr, get_cindex, get_rm2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "OUuvBi3AXoCM"
      },
      "outputs": [],
      "source": [
        "TABSY = \"\\t\"\n",
        "figdir = \"figures/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "FeqXxcL4cRe0"
      },
      "outputs": [],
      "source": [
        "def build_combined_onehot(FLAGS, NUM_FILTERS, FILTER_LENGTH1, FILTER_LENGTH2):\n",
        "    XDinput = Input(shape=(FLAGS.max_smi_len, FLAGS.charsmiset_size))\n",
        "    XTinput = Input(shape=(FLAGS.max_seq_len, FLAGS.charseqset_size))\n",
        "\n",
        "\n",
        "    encode_smiles = Conv1D(filters=NUM_FILTERS, kernel_size=FILTER_LENGTH1,  activation='relu', padding='valid',  strides=1)(XDinput)\n",
        "    encode_smiles = Conv1D(filters=NUM_FILTERS*2, kernel_size=FILTER_LENGTH1,  activation='relu', padding='valid',  strides=1)(encode_smiles)\n",
        "    encode_smiles = Conv1D(filters=NUM_FILTERS*3, kernel_size=FILTER_LENGTH1,  activation='relu', padding='valid',  strides=1)(encode_smiles)\n",
        "    encode_smiles = GlobalMaxPooling1D()(encode_smiles) #pool_size=pool_length[i]\n",
        "\n",
        "\n",
        "    encode_protein = Conv1D(filters=NUM_FILTERS, kernel_size=FILTER_LENGTH2,  activation='relu', padding='valid',  strides=1)(XTinput)\n",
        "    encode_protein = Conv1D(filters=NUM_FILTERS*2, kernel_size=FILTER_LENGTH2,  activation='relu', padding='valid',  strides=1)(encode_protein)\n",
        "    encode_protein = Conv1D(filters=NUM_FILTERS*3, kernel_size=FILTER_LENGTH2,  activation='relu', padding='valid',  strides=1)(encode_protein)\n",
        "    encode_protein = GlobalMaxPooling1D()(encode_protein)\n",
        "\n",
        "\n",
        "\n",
        "    encode_interaction = keras.layers.concatenate([encode_smiles, encode_protein])\n",
        "    #encode_interaction = keras.layers.concatenate([encode_smiles, encode_protein], axis=-1) #merge.Add()([encode_smiles, encode_protein])\n",
        "\n",
        "    # Fully connected\n",
        "    FC1 = Dense(1024, activation='relu')(encode_interaction)\n",
        "    FC2 = Dropout(0.1)(FC1)\n",
        "    FC2 = Dense(1024, activation='relu')(FC2)\n",
        "    FC2 = Dropout(0.1)(FC2)\n",
        "    FC2 = Dense(512, activation='relu')(FC2)\n",
        "\n",
        "\n",
        "    predictions = Dense(1, kernel_initializer='normal')(FC2)\n",
        "\n",
        "    interactionModel = Model(inputs=[XDinput, XTinput], outputs=[predictions])\n",
        "    interactionModel.compile(optimizer='adam', loss='mean_squared_error', metrics=[cindex_score]) #, metrics=['cindex_score']\n",
        "\n",
        "\n",
        "    print(interactionModel.summary())\n",
        "    plot_model(interactionModel, to_file='figures/build_combined_onehot.png')\n",
        "\n",
        "    return interactionModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "OS8VI4Q7cRMN"
      },
      "outputs": [],
      "source": [
        "def build_combined_categorical(FLAGS, NUM_FILTERS, FILTER_LENGTH1, FILTER_LENGTH2):\n",
        "\n",
        "    XDinput = Input(shape=(FLAGS.max_smi_len,), dtype='int32') ### Buralar flagdan gelmeliii\n",
        "    XTinput = Input(shape=(FLAGS.max_seq_len,), dtype='int32')\n",
        "\n",
        "    ### SMI_EMB_DINMS  FLAGS GELMELII\n",
        "    encode_smiles = Embedding(input_dim=FLAGS.charsmiset_size+1, output_dim=128, input_length=FLAGS.max_smi_len)(XDinput)\n",
        "    encode_smiles = Conv1D(filters=NUM_FILTERS, kernel_size=FILTER_LENGTH1,  activation='relu', padding='valid',  strides=1)(encode_smiles)\n",
        "    encode_smiles = Conv1D(filters=NUM_FILTERS*2, kernel_size=FILTER_LENGTH1,  activation='relu', padding='valid',  strides=1)(encode_smiles)\n",
        "    encode_smiles = Conv1D(filters=NUM_FILTERS*3, kernel_size=FILTER_LENGTH1,  activation='relu', padding='valid',  strides=1)(encode_smiles)\n",
        "    encode_smiles = GlobalMaxPooling1D()(encode_smiles)\n",
        "\n",
        "\n",
        "    encode_protein = Embedding(input_dim=FLAGS.charseqset_size+1, output_dim=128, input_length=FLAGS.max_seq_len)(XTinput)\n",
        "    encode_protein = Conv1D(filters=NUM_FILTERS, kernel_size=FILTER_LENGTH2,  activation='relu', padding='valid',  strides=1)(encode_protein)\n",
        "    encode_protein = Conv1D(filters=NUM_FILTERS*2, kernel_size=FILTER_LENGTH2,  activation='relu', padding='valid',  strides=1)(encode_protein)\n",
        "    encode_protein = Conv1D(filters=NUM_FILTERS*3, kernel_size=FILTER_LENGTH2,  activation='relu', padding='valid',  strides=1)(encode_protein)\n",
        "    encode_protein = GlobalMaxPooling1D()(encode_protein)\n",
        "\n",
        "\n",
        "    encode_interaction = keras.layers.concatenate([encode_smiles, encode_protein], axis=-1) #merge.Add()([encode_smiles, encode_protein])\n",
        "\n",
        "    # Fully connected\n",
        "    FC1 = Dense(1024, activation='relu')(encode_interaction)\n",
        "    FC2 = Dropout(0.1)(FC1)\n",
        "    FC2 = Dense(1024, activation='relu')(FC2)\n",
        "    FC2 = Dropout(0.1)(FC2)\n",
        "    FC2 = Dense(512, activation='relu')(FC2)\n",
        "\n",
        "\n",
        "    # And add a logistic regression on top\n",
        "    predictions = Dense(1, kernel_initializer='normal')(FC2) #OR no activation, rght now it's between 0-1, do I want this??? activation='sigmoid'\n",
        "\n",
        "    interactionModel = Model(inputs=[XDinput, XTinput], outputs=[predictions])\n",
        "\n",
        "    interactionModel.compile(optimizer='adam', loss='mean_squared_error', metrics=[cindex_score]) #, metrics=['cindex_score']\n",
        "    print(interactionModel.summary())\n",
        "    # plot_model(interactionModel, to_file='figures/build_combined_categorical.png')\n",
        "\n",
        "    return interactionModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "yLRmBnCZcRIX"
      },
      "outputs": [],
      "source": [
        "def build_single_drug(FLAGS, NUM_FILTERS, FILTER_LENGTH1, FILTER_LENGTH2):\n",
        "\n",
        "    interactionModel = Sequential()\n",
        "    XTmodel = Sequential()\n",
        "    XTmodel.add(Activation('linear', input_shape=(FLAGS.target_count,)))\n",
        "\n",
        "\n",
        "    encode_smiles = Sequential()\n",
        "    encode_smiles.add(Embedding(input_dim=FLAGS.charsmiset_size+1, output_dim=128, input_length=FLAGS.max_smi_len))\n",
        "    encode_smiles.add(Conv1D(filters=NUM_FILTERS, kernel_size=FILTER_LENGTH1,  activation='relu', padding='valid',  strides=1)) #input_shape=(MAX_SMI_LEN, SMI_EMBEDDING_DIMS)\n",
        "    encode_smiles.add(Conv1D(filters=NUM_FILTERS*2, kernel_size=FILTER_LENGTH1,  activation='relu', padding='valid',  strides=1))\n",
        "    encode_smiles.add(Conv1D(filters=NUM_FILTERS*3, kernel_size=FILTER_LENGTH1,  activation='relu', padding='valid',  strides=1))\n",
        "    encode_smiles.add(GlobalMaxPooling1D())\n",
        "\n",
        "\n",
        "    # interactionModel.add(Merge([encode_smiles, XTmodel], mode='concat', concat_axis=1))\n",
        "    # #interactionModel.add(layers.merge.Concatenate([XDmodel, XTmodel]))\n",
        "    interactionModel.add(layers.Concatenate([encode_smiles, XTmodel]))\n",
        "\n",
        "    # Fully connected\n",
        "    interactionModel.add(Dense(1024, activation='relu')) #1024\n",
        "    interactionModel.add(Dropout(0.1))\n",
        "    interactionModel.add(Dense(1024, activation='relu')) #1024\n",
        "    interactionModel.add(Dropout(0.1))\n",
        "    interactionModel.add(Dense(512, activation='relu'))\n",
        "\n",
        "\n",
        "    interactionModel.add(Dense(1, kernel_initializer='normal'))\n",
        "    interactionModel.compile(optimizer='adam', loss='mean_squared_error', metrics=[cindex_score])\n",
        "\n",
        "    print(interactionModel.summary())\n",
        "    plot_model(interactionModel, to_file='figures/build_single_drug.png')\n",
        "\n",
        "    return interactionModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "uxdHUOKYcRD8"
      },
      "outputs": [],
      "source": [
        "def build_single_prot(FLAGS, NUM_FILTERS, FILTER_LENGTH1, FILTER_LENGTH2):\n",
        "\n",
        "    interactionModel = Sequential()\n",
        "    XDmodel = Sequential()\n",
        "    XDmodel.add(Activation('linear', input_shape=(FLAGS.drugcount,)))\n",
        "\n",
        "\n",
        "    XTmodel1 = Sequential()\n",
        "    XTmodel1.add(Embedding(input_dim=FLAGS.charseqset_size+1, output_dim=128,  input_length=FLAGS.max_seq_len))\n",
        "    XTmodel1.add(Conv1D(filters=NUM_FILTERS, kernel_size=FILTER_LENGTH2,  activation='relu', padding='valid',  strides=1)) #input_shape=(MAX_SEQ_LEN, SEQ_EMBEDDING_DIMS)\n",
        "    XTmodel1.add(Conv1D(filters=NUM_FILTERS*2, kernel_size=FILTER_LENGTH2,  activation='relu', padding='valid',  strides=1))\n",
        "    XTmodel1.add(Conv1D(filters=NUM_FILTERS*3, kernel_size=FILTER_LENGTH2,  activation='relu', padding='valid',  strides=1))\n",
        "    XTmodel1.add(GlobalMaxPooling1D())\n",
        "\n",
        "\n",
        "    # interactionModel.add(Merge([XDmodel, XTmodel1], mode='concat', concat_axis=1))\n",
        "    interactionModel.add(layers.Concatenate([XDmodel, XTmodel1]))\n",
        "\n",
        "\n",
        "    # Fully connected\n",
        "    interactionModel.add(Dense(1024, activation='relu'))\n",
        "    interactionModel.add(Dropout(0.1))\n",
        "    interactionModel.add(Dense(1024, activation='relu'))\n",
        "    interactionModel.add(Dropout(0.1))\n",
        "    interactionModel.add(Dense(512, activation='relu'))\n",
        "\n",
        "    interactionModel.add(Dense(1, kernel_initializer='normal'))\n",
        "    interactionModel.compile(optimizer='adam', loss='mean_squared_error', metrics=[cindex_score])\n",
        "\n",
        "    print(interactionModel.summary())\n",
        "    plot_model(interactionModel, to_file='figures/build_single_protein.png')\n",
        "\n",
        "    return interactionModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "lryshfmMcQ-_"
      },
      "outputs": [],
      "source": [
        "def build_baseline(FLAGS, NUM_FILTERS, FILTER_LENGTH1, FILTER_LENGTH2):\n",
        "    interactionModel = Sequential()\n",
        "\n",
        "    XDmodel = Sequential()\n",
        "    XDmodel.add(Dense(1, activation='linear', input_shape=(FLAGS.drug_count, )))\n",
        "\n",
        "    XTmodel = Sequential()\n",
        "    XTmodel.add(Dense(1, activation='linear', input_shape=(FLAGS.target_count,)))\n",
        "\n",
        "\n",
        "    # interactionModel.add(Merge([XDmodel, XTmodel], mode='concat', concat_axis=1))\n",
        "    interactionModel.add(layers.Concatenate([XDmodel, XTmodel]))\n",
        "\n",
        "    # Fully connected\n",
        "    interactionModel.add(Dense(1024, activation='relu'))\n",
        "    interactionModel.add(Dropout(0.1))\n",
        "    interactionModel.add(Dense(1024, activation='relu'))\n",
        "    interactionModel.add(Dropout(0.1))\n",
        "    interactionModel.add(Dense(512, activation='relu'))\n",
        "\n",
        "    interactionModel.add(Dense(1, kernel_initializer='normal'))\n",
        "    interactionModel.compile(optimizer='adam', loss='mean_squared_error', metrics=[cindex_score])\n",
        "\n",
        "    print(interactionModel.summary())\n",
        "    plot_model(interactionModel, to_file='figures/build_baseline.png')\n",
        "\n",
        "    return interactionModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "84KtoMBqcS5r"
      },
      "outputs": [],
      "source": [
        "def build_baseline(FLAGS, NUM_FILTERS, FILTER_LENGTH1, FILTER_LENGTH2):\n",
        "    interactionModel = Sequential()\n",
        "\n",
        "    XDmodel = Sequential()\n",
        "    XDmodel.add(Dense(1, activation='linear', input_shape=(FLAGS.drug_count, )))\n",
        "\n",
        "    XTmodel = Sequential()\n",
        "    XTmodel.add(Dense(1, activation='linear', input_shape=(FLAGS.target_count,)))\n",
        "\n",
        "\n",
        "    # interactionModel.add(Merge([XDmodel, XTmodel], mode='concat', concat_axis=1))\n",
        "    interactionModel.add(layers.Concatenate([XDmodel, XTmodel]))\n",
        "\n",
        "    # Fully connected\n",
        "    interactionModel.add(Dense(1024, activation='relu'))\n",
        "    interactionModel.add(Dropout(0.1))\n",
        "    interactionModel.add(Dense(1024, activation='relu'))\n",
        "    interactionModel.add(Dropout(0.1))\n",
        "    interactionModel.add(Dense(512, activation='relu'))\n",
        "\n",
        "    interactionModel.add(Dense(1, kernel_initializer='normal'))\n",
        "    interactionModel.compile(optimizer='adam', loss='mean_squared_error', metrics=[cindex_score])\n",
        "\n",
        "    print(interactionModel.summary())\n",
        "    plot_model(interactionModel, to_file='figures/build_baseline.png')\n",
        "\n",
        "    return interactionModel\n",
        "\n",
        "def nfold_1_2_3_setting_sample(XD, XT,  Y, label_row_inds, label_col_inds, measure, runmethod,  FLAGS, dataset):\n",
        "\n",
        "    bestparamlist = []\n",
        "    test_set, outer_train_sets = dataset.read_sets(FLAGS)\n",
        "\n",
        "    foldinds = len(outer_train_sets)\n",
        "\n",
        "    test_sets = []\n",
        "    ## TRAIN AND VAL\n",
        "    val_sets = []\n",
        "    train_sets = []\n",
        "\n",
        "    #logger.info('Start training')\n",
        "    for val_foldind in range(foldinds):\n",
        "        val_fold = outer_train_sets[val_foldind]\n",
        "        val_sets.append(val_fold)\n",
        "        otherfolds = deepcopy(outer_train_sets)\n",
        "        otherfolds.pop(val_foldind)\n",
        "        otherfoldsinds = [item for sublist in otherfolds for item in sublist]\n",
        "        train_sets.append(otherfoldsinds)\n",
        "        test_sets.append(test_set)\n",
        "        print(\"val set\", str(len(val_fold)))\n",
        "        print(\"train set\", str(len(otherfoldsinds)))\n",
        "\n",
        "\n",
        "\n",
        "    bestparamind, best_param_list, bestperf, all_predictions_not_need, losses_not_need = general_nfold_cv(XD, XT,  Y, label_row_inds, label_col_inds,\n",
        "                                                                                                measure, runmethod, FLAGS, train_sets, val_sets)\n",
        "\n",
        "    #print(\"Test Set len\", str(len(test_set)))\n",
        "    #print(\"Outer Train Set len\", str(len(outer_train_sets)))\n",
        "    bestparam, best_param_list, bestperf, all_predictions, all_losses = general_nfold_cv(XD, XT,  Y, label_row_inds, label_col_inds,\n",
        "                                                                                                measure, runmethod, FLAGS, train_sets, test_sets)\n",
        "\n",
        "    testperf = all_predictions[bestparamind]##pointer pos\n",
        "\n",
        "    logging(\"---FINAL RESULTS-----\", FLAGS)\n",
        "    logging(\"best param index = %s,  best param = %.5f\" %\n",
        "            (bestparamind, bestparam), FLAGS)\n",
        "\n",
        "\n",
        "    testperfs = []\n",
        "    testloss= []\n",
        "\n",
        "    avgperf = 0.\n",
        "\n",
        "    for test_foldind in range(len(test_sets)):\n",
        "        foldperf = all_predictions[bestparamind][test_foldind]\n",
        "        foldloss = all_losses[bestparamind][test_foldind]\n",
        "        testperfs.append(foldperf)\n",
        "        testloss.append(foldloss)\n",
        "        avgperf += foldperf\n",
        "\n",
        "    avgperf = avgperf / len(test_sets)\n",
        "    avgloss = np.mean(testloss)\n",
        "    teststd = np.std(testperfs)\n",
        "\n",
        "    logging(\"Test Performance CI\", FLAGS)\n",
        "    logging(testperfs, FLAGS)\n",
        "    logging(\"Test Performance MSE\", FLAGS)\n",
        "    logging(testloss, FLAGS)\n",
        "\n",
        "    return avgperf, avgloss, teststd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "jQsKDDxzEzi-"
      },
      "outputs": [],
      "source": [
        "def general_nfold_cv(XD, XT,  Y, label_row_inds, label_col_inds, prfmeasure, runmethod, FLAGS, labeled_sets, val_sets): ## BURAYA DA FLAGS LAZIM????\n",
        "\n",
        "    paramset1 = FLAGS.num_windows                              #[32]#[32,  512] #[32, 128]  # filter numbers\n",
        "    paramset2 = FLAGS.smi_window_lengths                               #[4, 8]#[4,  32] #[4,  8] #filter length smi\n",
        "    paramset3 = FLAGS.seq_window_lengths                               #[8, 12]#[64,  256] #[64, 192]#[8, 192, 384]\n",
        "    epoch = FLAGS.num_epoch                                 #100\n",
        "    batchsz = FLAGS.batch_size                             #256\n",
        "\n",
        "    logging(\"---Parameter Search-----\", FLAGS)\n",
        "\n",
        "    w = len(val_sets)\n",
        "    h = len(paramset1) * len(paramset2) * len(paramset3)\n",
        "\n",
        "    all_predictions = [[0 for x in range(w)] for y in range(h)]\n",
        "    all_losses = [[0 for x in range(w)] for y in range(h)]\n",
        "    print(all_predictions)\n",
        "\n",
        "    for foldind in range(len(val_sets)):\n",
        "        valinds = val_sets[foldind]\n",
        "        labeledinds = labeled_sets[foldind]\n",
        "\n",
        "        Y_train = np.mat(np.copy(Y))\n",
        "\n",
        "        params = {}\n",
        "        XD_train = XD\n",
        "        XT_train = XT\n",
        "        trrows = label_row_inds[labeledinds]\n",
        "        trcols = label_col_inds[labeledinds]\n",
        "\n",
        "        XD_train = XD[trrows]\n",
        "        XT_train = XT[trcols]\n",
        "\n",
        "        train_drugs, train_prots,  train_Y = prepare_interaction_pairs(XD, XT, Y, trrows, trcols)\n",
        "\n",
        "        terows = label_row_inds[valinds]\n",
        "        tecols = label_col_inds[valinds]\n",
        "        #print(\"terows\", str(terows), str(len(terows)))\n",
        "        #print(\"tecols\", str(tecols), str(len(tecols)))\n",
        "\n",
        "        val_drugs, val_prots,  val_Y = prepare_interaction_pairs(XD, XT,  Y, terows, tecols)\n",
        "\n",
        "\n",
        "        pointer = 0\n",
        "\n",
        "        for param1ind in range(len(paramset1)): #hidden neurons\n",
        "            param1value = paramset1[param1ind]\n",
        "            for param2ind in range(len(paramset2)): #learning rate\n",
        "                param2value = paramset2[param2ind]\n",
        "\n",
        "                for param3ind in range(len(paramset3)):\n",
        "                    param3value = paramset3[param3ind]\n",
        "\n",
        "                    gridmodel = runmethod(FLAGS, param1value, param2value, param3value)\n",
        "                    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=15)\n",
        "                    gridres = gridmodel.fit(([np.array(train_drugs),np.array(train_prots) ]), np.array(train_Y), batch_size=batchsz, epochs=epoch,\n",
        "                            validation_data=( ([np.array(val_drugs), np.array(val_prots) ]), np.array(val_Y)),  shuffle=False, callbacks=[es] )\n",
        "\n",
        "\n",
        "                    predicted_labels = gridmodel.predict([np.array(val_drugs), np.array(val_prots) ])\n",
        "                    loss, rperf2 = gridmodel.evaluate(([np.array(val_drugs),np.array(val_prots) ]), np.array(val_Y), verbose=0)\n",
        "                    rperf = prfmeasure(val_Y, predicted_labels)\n",
        "                    rperf = rperf[0]\n",
        "\n",
        "\n",
        "                    logging(\"P1 = %d,  P2 = %d, P3 = %d, Fold = %d, CI-i = %f, CI-ii = %f, MSE = %f\" %\n",
        "                    (param1ind, param2ind, param3ind, foldind, rperf, rperf2, loss), FLAGS)\n",
        "\n",
        "                    plotLoss(gridres, param1ind, param2ind, param3ind, foldind)\n",
        "\n",
        "                    all_predictions[pointer][foldind] =rperf #TODO FOR EACH VAL SET allpredictions[pointer][foldind]\n",
        "                    all_losses[pointer][foldind]= loss\n",
        "\n",
        "                    pointer +=1\n",
        "\n",
        "    bestperf = -float('Inf')\n",
        "    bestpointer = None\n",
        "\n",
        "\n",
        "    best_param_list = []\n",
        "    ##Take average according to folds, then chooose best params\n",
        "    pointer = 0\n",
        "    for param1ind in range(len(paramset1)):\n",
        "            for param2ind in range(len(paramset2)):\n",
        "                for param3ind in range(len(paramset3)):\n",
        "\n",
        "                    avgperf = 0.\n",
        "                    for foldind in range(len(val_sets)):\n",
        "                        foldperf = all_predictions[pointer][foldind]\n",
        "                        avgperf += foldperf\n",
        "                    avgperf /= len(val_sets)\n",
        "                    #print(epoch, batchsz, avgperf)\n",
        "                    if avgperf > bestperf:\n",
        "                        bestperf = avgperf\n",
        "                        bestpointer = pointer\n",
        "                        best_param_list = [param1ind, param2ind, param3ind]\n",
        "\n",
        "                    pointer +=1\n",
        "\n",
        "    return  bestpointer, best_param_list, bestperf, all_predictions, all_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "5RKTPBz9cuTy"
      },
      "outputs": [],
      "source": [
        "def cindex_score(y_true, y_pred):\n",
        "\n",
        "    g = tf.subtract(tf.expand_dims(y_pred, -1), y_pred)\n",
        "    g = tf.cast(g == 0.0, tf.float32) * 0.5 + tf.cast(g > 0.0, tf.float32)\n",
        "\n",
        "    f = tf.subtract(tf.expand_dims(y_true, -1), y_true) > 0.0\n",
        "    f = tf.compat.v1.matrix_band_part(tf.cast(f, tf.float32), -1, 0)\n",
        "\n",
        "    g = tf.reduce_sum(tf.multiply(g, f))\n",
        "    f = tf.reduce_sum(f)\n",
        "\n",
        "    return tf.where(tf.equal(g, 0), 0.0, g/f) #select"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "X3j085CqcuP8"
      },
      "outputs": [],
      "source": [
        "def plotLoss(history, batchind, epochind, param3ind, foldind):\n",
        "\n",
        "    figname = \"b\"+str(batchind) + \"_e\" + str(epochind) + \"_\" + str(param3ind) + \"_\"  + str( foldind) + \"_\" + str(time.time())\n",
        "    plt.figure()\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "\t#plt.legend(['trainloss', 'valloss', 'cindex', 'valcindex'], loc='upper left')\n",
        "    plt.legend(['trainloss', 'valloss'], loc='upper left')\n",
        "    plt.savefig(\"figures/\"+figname +\".png\" , dpi=None, facecolor='w', edgecolor='w', orientation='portrait',\n",
        "                    papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "    ## PLOT CINDEX\n",
        "    plt.figure()\n",
        "    plt.title('model concordance index')\n",
        "    plt.ylabel('cindex')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.plot(history.history['cindex_score'])\n",
        "    plt.plot(history.history['val_cindex_score'])\n",
        "    plt.legend(['traincindex', 'valcindex'], loc='upper left')\n",
        "    plt.savefig(\"figures/\"+figname + \"_acc.png\" , dpi=None, facecolor='w', edgecolor='w', orientation='portrait',\n",
        "                            papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "k6woDI0ocSzm"
      },
      "outputs": [],
      "source": [
        "def prepare_interaction_pairs(XD, XT,  Y, rows, cols):\n",
        "    drugs = []\n",
        "    targets = []\n",
        "    targetscls = []\n",
        "    affinity=[]\n",
        "\n",
        "    for pair_ind in range(len(rows)):\n",
        "        drug = XD[rows[pair_ind]]\n",
        "        drugs.append(drug)\n",
        "\n",
        "        target=XT[cols[pair_ind]]\n",
        "        targets.append(target)\n",
        "\n",
        "        affinity.append(Y[rows[pair_ind],cols[pair_ind]])\n",
        "\n",
        "    drug_data = np.stack(drugs)\n",
        "    target_data = np.stack(targets)\n",
        "\n",
        "    return drug_data,target_data,  affinity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "PoFYZXIxcniE"
      },
      "outputs": [],
      "source": [
        "def experiment(FLAGS, perfmeasure, deepmethod, foldcount=6): #5-fold cross validation + test\n",
        "\n",
        "    #Input\n",
        "    #XD: [drugs, features] sized array (features may also be similarities with other drugs\n",
        "    #XT: [targets, features] sized array (features may also be similarities with other targets\n",
        "    #Y: interaction values, can be real values or binary (+1, -1), insert value float(\"nan\") for unknown entries\n",
        "    #perfmeasure: function that takes as input a list of correct and predicted outputs, and returns performance\n",
        "    #higher values should be better, so if using error measures use instead e.g. the inverse -error(Y, P)\n",
        "    #foldcount: number of cross-validation folds for settings 1-3, setting 4 always runs 3x3 cross-validation\n",
        "\n",
        "\n",
        "    dataset = DataSet( fpath = FLAGS.dataset_path, ### BUNU ARGS DA GUNCELLE\n",
        "                      setting_no = FLAGS.problem_type, ##BUNU ARGS A EKLE\n",
        "                      seqlen = FLAGS.max_seq_len,\n",
        "                      smilen = FLAGS.max_smi_len,\n",
        "                      need_shuffle = False )\n",
        "    # set character set size\n",
        "    FLAGS.charseqset_size = dataset.charseqset_size\n",
        "    FLAGS.charsmiset_size = dataset.charsmiset_size\n",
        "\n",
        "    XD, XT, Y = dataset.parse_data(FLAGS)\n",
        "\n",
        "    XD = np.asarray(XD)\n",
        "    XT = np.asarray(XT)\n",
        "    Y = np.asarray(Y)\n",
        "\n",
        "    drugcount = XD.shape[0]\n",
        "    print(drugcount)\n",
        "    targetcount = XT.shape[0]\n",
        "    print(targetcount)\n",
        "\n",
        "    FLAGS.drug_count = drugcount\n",
        "    FLAGS.target_count = targetcount\n",
        "\n",
        "    label_row_inds, label_col_inds = np.where(np.isnan(Y)==False)  #basically finds the point address of affinity [x,y]\n",
        "\n",
        "    if not os.path.exists(figdir):\n",
        "        os.makedirs(figdir)\n",
        "\n",
        "    print(FLAGS.log_dir)\n",
        "    S1_avgperf, S1_avgloss, S1_teststd = nfold_1_2_3_setting_sample(XD, XT, Y, label_row_inds, label_col_inds,\n",
        "                                                                     perfmeasure, deepmethod, FLAGS, dataset)\n",
        "\n",
        "    logging(\"Setting \" + str(FLAGS.problem_type), FLAGS)\n",
        "    logging(\"avg_perf = %.5f,  avg_mse = %.5f, std = %.5f\" %\n",
        "            (S1_avgperf, S1_avgloss, S1_teststd), FLAGS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "X1v8eF0Icne8"
      },
      "outputs": [],
      "source": [
        "def run_regression( FLAGS ):\n",
        "\n",
        "    perfmeasure = get_cindex\n",
        "    deepmethod = build_combined_categorical\n",
        "\n",
        "    experiment(FLAGS, perfmeasure, deepmethod)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Z6e28Qic_2p",
        "outputId": "61d4677d-f9a9-4dbc-86f0-b79d2d958ab0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read data/kiba/ start\n",
            "2111\n",
            "229\n",
            "logs/1691942762.6542764/\n",
            "Reading data/kiba/ start\n",
            "val set 19709\n",
            "train set 78836\n",
            "val set 19709\n",
            "train set 78836\n",
            "val set 19709\n",
            "train set 78836\n",
            "val set 19709\n",
            "train set 78836\n",
            "val set 19709\n",
            "train set 78836\n",
            "[[0, 0, 0, 0, 0]]\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 100)]        0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 1000)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 100, 128)     8320        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 1000, 128)    3328        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 97, 32)       16416       ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)              (None, 993, 32)      32800       ['embedding_1[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 94, 64)       8256        ['conv1d[0][0]']                 \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)              (None, 986, 64)      16448       ['conv1d_3[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 91, 96)       24672       ['conv1d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)              (None, 979, 96)      49248       ['conv1d_4[0][0]']               \n",
            "                                                                                                  \n",
            " global_max_pooling1d (GlobalMa  (None, 96)          0           ['conv1d_2[0][0]']               \n",
            " xPooling1D)                                                                                      \n",
            "                                                                                                  \n",
            " global_max_pooling1d_1 (Global  (None, 96)          0           ['conv1d_5[0][0]']               \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 192)          0           ['global_max_pooling1d[0][0]',   \n",
            "                                                                  'global_max_pooling1d_1[0][0]'] \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1024)         197632      ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 1024)         0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1024)         1049600     ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 1024)         0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 512)          524800      ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 1)            513         ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,932,033\n",
            "Trainable params: 1,932,033\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "308/308 [==============================] - 29s 39ms/step - loss: 3.0698 - cindex_score: 0.5991 - val_loss: 0.5184 - val_cindex_score: 0.7100\n",
            "Epoch 2/50\n",
            "308/308 [==============================] - 9s 30ms/step - loss: 0.5981 - cindex_score: 0.6732 - val_loss: 0.4716 - val_cindex_score: 0.7308\n",
            "Epoch 3/50\n",
            "308/308 [==============================] - 9s 30ms/step - loss: 0.5644 - cindex_score: 0.6982 - val_loss: 0.4647 - val_cindex_score: 0.7402\n",
            "Epoch 4/50\n",
            "308/308 [==============================] - 9s 29ms/step - loss: 0.5475 - cindex_score: 0.7110 - val_loss: 0.4802 - val_cindex_score: 0.7454\n",
            "Epoch 5/50\n",
            "308/308 [==============================] - 9s 30ms/step - loss: 0.5214 - cindex_score: 0.7191 - val_loss: 0.4613 - val_cindex_score: 0.7497\n",
            "Epoch 6/50\n",
            "308/308 [==============================] - 9s 30ms/step - loss: 0.5008 - cindex_score: 0.7238 - val_loss: 0.4198 - val_cindex_score: 0.7505\n",
            "Epoch 7/50\n",
            "308/308 [==============================] - 9s 31ms/step - loss: 0.5036 - cindex_score: 0.7269 - val_loss: 0.4091 - val_cindex_score: 0.7522\n",
            "Epoch 8/50\n",
            "308/308 [==============================] - 9s 30ms/step - loss: 0.4829 - cindex_score: 0.7295 - val_loss: 0.4055 - val_cindex_score: 0.7533\n",
            "Epoch 9/50\n",
            "308/308 [==============================] - 9s 29ms/step - loss: 0.4939 - cindex_score: 0.7308 - val_loss: 0.5109 - val_cindex_score: 0.7504\n",
            "Epoch 10/50\n",
            "308/308 [==============================] - 9s 30ms/step - loss: 0.4881 - cindex_score: 0.7330 - val_loss: 0.3983 - val_cindex_score: 0.7556\n",
            "Epoch 11/50\n",
            "308/308 [==============================] - 9s 30ms/step - loss: 0.4722 - cindex_score: 0.7352 - val_loss: 0.4024 - val_cindex_score: 0.7552\n",
            "Epoch 12/50\n",
            "308/308 [==============================] - 9s 30ms/step - loss: 0.4586 - cindex_score: 0.7383 - val_loss: 0.4023 - val_cindex_score: 0.7573\n",
            "Epoch 13/50\n",
            "308/308 [==============================] - 9s 30ms/step - loss: 0.4541 - cindex_score: 0.7403 - val_loss: 0.4110 - val_cindex_score: 0.7619\n",
            "Epoch 14/50\n",
            "308/308 [==============================] - 9s 29ms/step - loss: 0.4322 - cindex_score: 0.7443 - val_loss: 0.3712 - val_cindex_score: 0.7656\n",
            "Epoch 15/50\n",
            "308/308 [==============================] - 9s 30ms/step - loss: 0.4101 - cindex_score: 0.7491 - val_loss: 0.3558 - val_cindex_score: 0.7695\n",
            "Epoch 16/50\n",
            "308/308 [==============================] - 10s 31ms/step - loss: 0.3957 - cindex_score: 0.7528 - val_loss: 0.3428 - val_cindex_score: 0.7745\n",
            "Epoch 17/50\n",
            "308/308 [==============================] - 9s 29ms/step - loss: 0.3924 - cindex_score: 0.7552 - val_loss: 0.3418 - val_cindex_score: 0.7775\n",
            "Epoch 18/50\n",
            "308/308 [==============================] - 9s 30ms/step - loss: 0.3764 - cindex_score: 0.7606 - val_loss: 0.3337 - val_cindex_score: 0.7816\n",
            "Epoch 19/50\n",
            "308/308 [==============================] - 9s 30ms/step - loss: 0.3639 - cindex_score: 0.7647 - val_loss: 0.3258 - val_cindex_score: 0.7861\n",
            "Epoch 20/50\n",
            "308/308 [==============================] - 9s 30ms/step - loss: 0.3526 - cindex_score: 0.7674 - val_loss: 0.3244 - val_cindex_score: 0.7896\n",
            "Epoch 21/50\n",
            "308/308 [==============================] - 9s 30ms/step - loss: 0.3513 - cindex_score: 0.7699 - val_loss: 0.3120 - val_cindex_score: 0.7961\n",
            "Epoch 22/50\n",
            "308/308 [==============================] - 9s 30ms/step - loss: 0.3440 - cindex_score: 0.7730 - val_loss: 0.3279 - val_cindex_score: 0.7962\n",
            "Epoch 23/50\n",
            "308/308 [==============================] - 9s 30ms/step - loss: 0.3353 - cindex_score: 0.7763 - val_loss: 0.3379 - val_cindex_score: 0.7970\n",
            "Epoch 24/50\n",
            "308/308 [==============================] - 9s 30ms/step - loss: 0.3279 - cindex_score: 0.7778 - val_loss: 0.3101 - val_cindex_score: 0.7997\n",
            "Epoch 25/50\n",
            "308/308 [==============================] - 9s 30ms/step - loss: 0.3182 - cindex_score: 0.7809 - val_loss: 0.3155 - val_cindex_score: 0.7991\n",
            "Epoch 26/50\n",
            "308/308 [==============================] - 9s 30ms/step - loss: 0.3109 - cindex_score: 0.7835 - val_loss: 0.3034 - val_cindex_score: 0.8005\n",
            "Epoch 27/50\n",
            "308/308 [==============================] - 9s 29ms/step - loss: 0.3018 - cindex_score: 0.7870 - val_loss: 0.2959 - val_cindex_score: 0.8023\n",
            "Epoch 28/50\n",
            "308/308 [==============================] - 9s 30ms/step - loss: 0.2933 - cindex_score: 0.7903 - val_loss: 0.2829 - val_cindex_score: 0.8074\n",
            "Epoch 29/50\n",
            "308/308 [==============================] - 10s 32ms/step - loss: 0.2872 - cindex_score: 0.7949 - val_loss: 0.2756 - val_cindex_score: 0.8080\n",
            "Epoch 30/50\n",
            "308/308 [==============================] - 9s 29ms/step - loss: 0.2721 - cindex_score: 0.7998 - val_loss: 0.2636 - val_cindex_score: 0.8145\n",
            "Epoch 31/50\n",
            "308/308 [==============================] - 9s 30ms/step - loss: 0.2621 - cindex_score: 0.8028 - val_loss: 0.2716 - val_cindex_score: 0.8139\n",
            "Epoch 32/50\n",
            "308/308 [==============================] - 9s 30ms/step - loss: 0.2563 - cindex_score: 0.8065 - val_loss: 0.2630 - val_cindex_score: 0.8125\n",
            "Epoch 33/50\n",
            "308/308 [==============================] - 9s 30ms/step - loss: 0.2459 - cindex_score: 0.8091 - val_loss: 0.2700 - val_cindex_score: 0.8145\n",
            "Epoch 34/50\n",
            "308/308 [==============================] - 9s 30ms/step - loss: 0.2345 - cindex_score: 0.8123 - val_loss: 0.2498 - val_cindex_score: 0.8210\n",
            "Epoch 35/50\n",
            "261/308 [========================>.....] - ETA: 1s - loss: 0.2295 - cindex_score: 0.8149"
          ]
        }
      ],
      "source": [
        "# if __name__==\"__main__\":\n",
        "\n",
        "FLAGS = argparser()\n",
        "FLAGS.num_windows = [32]\n",
        "FLAGS.seq_window_lengths = [8]#[8,12]\n",
        "FLAGS.smi_window_lengths = [4]#[4,8]\n",
        "FLAGS.batch_size = 256\n",
        "FLAGS.num_epoch = 50\n",
        "FLAGS.max_seq_len = 1000\n",
        "FLAGS.max_smi_len = 100\n",
        "FLAGS.dataset_path = 'data/kiba/'\n",
        "FLAGS.problem_type = 1\n",
        "FLAGS.log_dir = 'logs/' + str(time.time()) + \"/\"\n",
        "\n",
        "if not os.path.exists(FLAGS.log_dir):\n",
        "  os.makedirs(FLAGS.log_dir)\n",
        "\n",
        "logging(str(FLAGS), FLAGS)\n",
        "run_regression( FLAGS )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zesQSJVMblIi"
      },
      "outputs": [],
      "source": [
        "ls -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0RIuKqBcK8s"
      },
      "outputs": [],
      "source": [
        "# pip list | grep matplotlib"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}